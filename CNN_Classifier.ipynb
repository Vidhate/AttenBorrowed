{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source - https://www.kaggle.com/montimirko/digit-recognition-with-cnn-0-99-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src=Path(\"./Source Data/\")\n",
    "train_src=src/'mnist_train.csv'\n",
    "test_src=src/'mnist_test.csv'\n",
    "# Should be able to use numpy.loadtxt to load these CSVs\n",
    "df_train=pd.read_csv(train_src,header=None)\n",
    "df_test=pd.read_csv(test_src,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (10000,)\n",
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Structure of CSV is a single linear list of 1+784 normalized values for each 28X28 image where the 1st value is the label\n",
    "# This cell strips the labels from the image data and stores in different variables\n",
    "train_labels=df_train.iloc[:,0].values\n",
    "train_set=df_train.drop(df_train.columns[0],axis=1).values\n",
    "test_labels=df_test.iloc[:,0].values\n",
    "test_set=df_test.drop(df_test.columns[0],axis=1).values\n",
    "\n",
    "print(train_labels.shape,test_labels.shape)\n",
    "print(train_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "(60000, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Need to reshape the data as a 4D tensor form because Conv2D (the convolution layer from tensorflow) takes input as 4D tensor\n",
    "train_set=np.reshape(train_set,(-1,28,28,1))\n",
    "test_set=np.reshape(test_set,(-1,28,28,1))\n",
    "train_labels=np.reshape(train_labels,(-1,1))\n",
    "test_labels=np.reshape(test_labels,(-1,1))\n",
    "\n",
    "print(train_set.shape,test_set.shape)\n",
    "print(train_labels.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17145b130f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To see any of the images use imshow\n",
    "plt.imshow(train_set[7000].reshape([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vidhate\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Documentation for adding layers to the sequential model\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "model=keras.models.Sequential([\n",
    "    # doc on conv layer - https://keras.io/layers/convolutional/\n",
    "    keras.layers.Conv2D(64, (3,3), input_shape=(28,28,1), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    # doc to explain padding -https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n",
    "    keras.layers.Conv2D(128, (3,3),padding='valid', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3,3),padding='valid', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(64),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 249,546\n",
      "Trainable params: 248,522\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# doc on categorical crossentropy - https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy\n",
    "# Why sparse categorical crossentropy is better than normal categorical entropy -\n",
    "# https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain,Xtest,Ytrain,Ytest=train_test_split(train_set,train_labels,test_size=0.2)\n",
    "#print(Xtrain.shape,Ytrain.shape,Xtest.shape,Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 203s 3ms/sample - loss: 0.0735 - acc: 0.9778\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 207s 3ms/sample - loss: 0.0533 - acc: 0.9836\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 210s 3ms/sample - loss: 0.0392 - acc: 0.9876\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 208s 3ms/sample - loss: 0.0323 - acc: 0.9900\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 209s 3ms/sample - loss: 0.0274 - acc: 0.9913\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 208s 3ms/sample - loss: 0.0240 - acc: 0.9924\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 208s 3ms/sample - loss: 0.0175 - acc: 0.9941\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 212s 4ms/sample - loss: 0.0171 - acc: 0.9945\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 209s 3ms/sample - loss: 0.0136 - acc: 0.9956\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 203s 3ms/sample - loss: 0.0134 - acc: 0.9956\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_set,train_labels,epochs=10)\n",
    "# history stores the loss across the training epochs. \n",
    "# Ref - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 0.0452 - acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04519553901469335, 0.9889]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
